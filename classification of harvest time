from __future__ import print_function
import numpy as np
import scipy.io
import scipy.linalg
import sklearn.metrics
from sklearn import svm
from scipy.io import loadmat
import numpy as np
import random
from xgboost import XGBClassifier
from lightgbm.sklearn import LGBMClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score
import pandas as pd
from pandas import DataFrame as df
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt   
def kernel(ker, X1, X2, gamma):
    K = None
    if not ker or ker == 'primal':
        K = X1
    elif ker == 'linear':
        if X2 is not None:
            K = sklearn.metrics.pairwise.linear_kernel(np.asarray(X1).T, np.asarray(X2).T)
        else:
            K = sklearn.metrics.pairwise.linear_kernel(np.asarray(X1).T)
    elif ker == 'rbf':
        if X2 is not None:
            K = sklearn.metrics.pairwise.rbf_kernel(np.asarray(X1).T, np.asarray(X2).T, gamma)
        else:
            K = sklearn.metrics.pairwise.rbf_kernel(np.asarray(X1).T, None, gamma)
    return K


class TCA:
    def __init__(self, kernel_type='primal', dim=10, lamb=1, gamma=1):
        '''
        Init func
        :param kernel_type: kernel, values: 'primal' | 'linear' | 'rbf'
        :param dim: dimension after transfer
        :param lamb: lambda value in equation
        :param gamma: kernel bandwidth for rbf kernel
        '''
        self.kernel_type = kernel_type
        self.dim = dim
        self.lamb = lamb
        self.gamma = gamma

    def fit(self, Xs, Xt):
        '''
        Transform Xs and Xt
        :param Xs: ns * n_feature, source feature
        :param Xt: nt * n_feature, target feature
        :return: Xs_new and Xt_new after TCA
        '''
        X = np.hstack((Xs.T, Xt.T))
        X /= np.linalg.norm(X, axis=0)
        m, n = X.shape
        ns, nt = len(Xs), len(Xt)
        e = np.vstack((1 / ns * np.ones((ns, 1)), -1 / nt * np.ones((nt, 1))))
        M = e * e.T
        M = M / np.linalg.norm(M, 'fro')
        H = np.eye(n) - 1 / n * np.ones((n, n))
        K = kernel(self.kernel_type, X, None, gamma=self.gamma)
        n_eye = m if self.kernel_type == 'primal' else n
        a, b = np.linalg.multi_dot([K, M, K.T]) + self.lamb * np.eye(n_eye), np.linalg.multi_dot([K, H, K.T])
        w, V = scipy.linalg.eig(a, b)
        ind = np.argsort(w)
        A = V[:, ind[:self.dim]]
        Z = np.dot(A.T, K)
        Z /= np.linalg.norm(Z, axis=0)
        Xs_new, Xt_new = Z[:, :ns].T, Z[:, ns:].T
        return Xs_new, Xt_new

    def fit_predict(self, Xs, Ys, Xt, Yt):
        '''
        Transform Xs and Xt, then make predictions on target using 1NN
        :param Xs: ns * n_feature, source feature
        :param Ys: ns * 1, source label
        :param Xt: nt * n_feature, target feature
        :param Yt: nt * 1, target label
        :return: Accuracy and predicted_labels on the target domain
        '''
        Xs_new, Xt_new = self.fit(Xs, Xt)
 
    
    
        '''
        lightgbm
        '''    
        clf = LGBMClassifier(num_leaves=150,learning_rate=1.1)
        clf.fit(Xs_new, Ys.ravel())
        y_test_pred=clf.predict(Xt_new)
#        y_train_pred=clf.predict(Xs_new)
        acctest = sklearn.metrics.accuracy_score(Yt, y_test_pred)
        print("%.2f%% " % (acctest4*100))
#        acctrain = accuracy_score(Ys, y_train_pred)
#        f1score = f1_score(Yt, y_test_pred4, average='macro')
#        return acctest, acctrain
        
        return acctest,Xs_new,Xt_new

    
    



if __name__ == '__main__':


      M1=loadmat("C:/Users/wxr/onedrive/桌面/采摘时间区分/梅家坞产区/Data.mat")
      num=25
      n=num-1
      s=0
      M2=M1['Data']
      

      
      
      sum1,sum2,sum3,sum4=0,0,0,0
      for i in range(10):
          x1=df()
          x2=df()
          x3=df()
          xsrc=df()
          ysrc=df()
          Data=pd.DataFrame(M2)
          Y_tar=Data.loc[180:1259,10]

          D1=Data.loc[0:179,:]
          D1=D1.reset_index(drop=True)  #更新index #
    
          D2=Data.loc[180:359,:]
          D2=D2.reset_index(drop=True) 
    
          D3=Data.loc[360:539,:]
          D3=D3.reset_index(drop=True)
     
          D4=Data.loc[540:719,:]
          D4=D4.reset_index(drop=True) 
    
          D5=Data.loc[720:899,:]
          D5=D5.reset_index(drop=True) 
        
          D6=Data.loc[900:1079,:]
          D6=D6.reset_index(drop=True)
         
          D7=Data.loc[1080:1259,:]
          D7=D7.reset_index(drop=True) 
          for N in [D2,D3,D4,D5,D6,D7]:
                N1=N.loc[0:89,:]
                N2=N.loc[90:179,:]
                W1=np.matrix(N1)
                W2=np.matrix(N2)
                np.random.shuffle(W1)
                np.random.shuffle(W2)
                x1=pd.DataFrame(W1, None)
                x2=pd.DataFrame(W2, None)
                X1=x1.loc[0:n,0:9]
                X2=x2.loc[0:n,0:9]
                Y1=x1.loc[0:n,10]
                Y2=x2.loc[0:n,10]
                u=pd.concat([Y1,Y2])
                U=u.reset_index(drop=True)
                U=U.to_frame()
                z=pd.concat([X1,X2])
                Z=z.reset_index(drop=True)
                xsrc=xsrc.append(Z)
                ysrc=ysrc.append(U)        
                o=D1.loc[:,0:9]
                X_src=np.vstack((o,xsrc))
                p=D1.loc[:,10]
                p=p.to_frame()
                Y_src=np.vstack((p,ysrc))
                xtar=pd.concat([D2,D3,D4,D5,D6,D7])
                x_tar=xtar.reset_index(drop=True)
                X_tar=x_tar.loc[:,0:9] 
          
          Xs=X_src
          Ys=Y_src
          Xt=X_tar
          Yt=Y_tar
          tca = TCA(kernel_type='primal' , dim=10, lamb=1, gamma=1)
          acctest4,Xs_new,Xt_new= tca.fit_predict(Xs, Ys, Xt, Yt)
          sum4+=acctest4
          s=s+1
          print(s)

      acc=sum4/10
      print("\n%.2f%% " % (acc*100))
